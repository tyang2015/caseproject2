{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694439fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c53572",
   "metadata": {},
   "source": [
    "# Define Classes: Recommender and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b79fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self, data, user_col, item_cols, cf_method='item', similarity='pearson'):\n",
    "        '''init Recommender class'''\n",
    "        self.data = data\n",
    "        self.user_col = user_col\n",
    "        self.item_cols = item_cols\n",
    "        self.cf_method = cf_method\n",
    "        self.similarity = similarity\n",
    "        self.similarity_matrix = []\n",
    "        self.user_scores = []\n",
    "        self.recs = []\n",
    "\n",
    "    def create_similarity_matrix(self):\n",
    "        '''creates correlation/similarity matrix for all items and stores results in self.similarity_matrix'''\n",
    "        print('creating matrix...')\n",
    "        self.similarity_matrix = self._create_empty_df(self.cf_method)\n",
    "        self._fill_similarity_matrix(self.similarity_matrix, self.similarity)\n",
    "\n",
    "    def score_users(self, users=None):\n",
    "        '''generates item ratings for each item for each user and stores result as self.user_scores'''\n",
    "        'generate user scores for entirely new dataframe. (batch creation)'\n",
    "        if not users:\n",
    "            # grab all users in data by default\n",
    "            users = self.data.loc[:,self.user_col]\n",
    "        cols = [self.user_col] + list(self.item_cols)\n",
    "        user_data = self.data.loc[:,cols].set_index(self.user_col)\n",
    "        self.user_scores = pd.DataFrame(index=users, columns=self.item_cols)\n",
    "        self.user_scores = self.data[self.item_cols].dot(self.similarity_matrix)\n",
    "        self.user_scores[self.user_col]=users\n",
    "        self.user_scores= self.user_scores.set_index(self.user_col)\n",
    "        print(self.user_scores)\n",
    "\n",
    "\n",
    "    def score_new_users(self, users, user_data):\n",
    "        '''generates item ratings for users passed in from external data set and stores result as self.user_scores'''\n",
    "        #adding new users to an existing dataframe which we built in 'score_users'\n",
    "        cols = [self.user_col] + list(self.item_cols)\n",
    "        self.user_scores = pd.DataFrame(index=user_data.index, columns=self.item_cols)\n",
    "        self.user_scores = user_data.loc[self.item_cols].dot(self.similarity_matrix)      \n",
    "                \n",
    "    def generate_recs(self, users=None, num_recs=3):\n",
    "        '''generates top num_rec recommendations for users and stores result as self.recs'''\n",
    "        print('We hope you will find these recommended items to your satisfaction should you purchase in the future!\\nThank you for shopping with us')\n",
    "        if not users:\n",
    "            # grab all users in data by default\n",
    "            users = self.data.loc[:,self.user_col]\n",
    "        cols = ['Rec ' + str(x) for x in range(1,num_recs+1)] + ['Score ' + str(x) for x in range(1,num_recs+1)]\n",
    "        self.recs = pd.DataFrame(index=users, columns=cols)\n",
    "        #create dataframe that will list the recommendations by each row, labeled by Member_number\n",
    "        progress_bar = tqdm(total = len(users), mininterval=10)\n",
    "        for user in users:\n",
    "            progress_bar.update()\n",
    "            sorted_items = self.user_scores.sort_values(by=user, ascending=False, axis=1).loc[user,:].index\n",
    "            for i in range(num_recs):\n",
    "                item = sorted_items[i]\n",
    "                item_col = cols[i]\n",
    "                score_col = cols[i+num_recs]\n",
    "                self.recs.loc[user, item_col] = item\n",
    "                self.recs.loc[user, score_col] = self.user_scores.loc[user, item]\n",
    "        self.recs.reset_index(inplace=True, drop=False)\n",
    "       \n",
    "        \n",
    "    def print_recs(self):\n",
    "        print(self.recs)\n",
    "        \n",
    "    def save_recs(self, filename='recommendations', format='excel'):\n",
    "        '''saves self.recs to filename in specified format'''\n",
    "        if format == 'excel':\n",
    "            extension ='.xlsx'\n",
    "            self.recs.to_excel(filename + extension, index=False)\n",
    "        elif format == 'csv':\n",
    "            extension += '.csv'\n",
    "            self.recs.to_csv(filename + extension, index=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid file format.  Please specify \"excel\" or \"csv\".')\n",
    "  \n",
    "    def _create_empty_df(self, cf_type):\n",
    "        '''creates and returns empty df with users or items as rows and columns'''\n",
    "        if cf_type == 'item':\n",
    "            labels = self.item_cols\n",
    "        elif cf_type == 'user':\n",
    "            labels = self.data[user_col]\n",
    "        else:\n",
    "            raise ValueError('Invalid collaborative filtering type.  Please specify \"item\" or \"user\".')\n",
    "        return pd.DataFrame(index=labels, columns=labels)\n",
    "\n",
    "    def _fill_similarity_matrix(self, similarity_matrix, similarity):\n",
    "        '''calculates correlation between items using specified similarity and saves results in NxN similarity_matrix\n",
    "           3 similarity types: jaccard, pearson, cosine. Jaccard will be used in this case project.'''\n",
    "        progress_bar = tqdm(total = similarity_matrix.shape[0], mininterval=5)\n",
    "        item_df = self.data[self.item_cols]   \n",
    "        for i in range(similarity_matrix.shape[0]):\n",
    "            progress_bar.update()\n",
    "            similarity_matrix.iloc[i,i] = 1.0\n",
    "            #this reduces the computation time in get_similarity\n",
    "            x = item_df.iloc[:,i]\n",
    "            for j in range(i,similarity_matrix.shape[1]):\n",
    "                y = item_df.iloc[:,j]\n",
    "                similarity_matrix.iloc[i,j] = self._get_similarity(x, y, similarity)\n",
    "                similarity_matrix.iloc[j,i] = similarity_matrix.iloc[i, j]\n",
    "                '''each x column represents an item column. so when we perform jaccard similarity, the union and intersection calculated\n",
    "        each time is with each pairing of columns, or pairing of vectors. Skip same item pairings with correlation of 1'''\n",
    "\n",
    "                \n",
    "    def _get_similarity(self, x, y, similarity):\n",
    "        '''find similarity metric and determine correlation between two vectors and return result'''\n",
    "        if similarity == 'pearson':\n",
    "            return self._pearson_similarity(x, y)\n",
    "        elif similarity == 'jaccard':\n",
    "            return self._jaccard_similarity(x, y)\n",
    "        elif similarity == 'cosine':\n",
    "            return self._cosine_similarity(x, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid similarity type.  Please specify \"cosine\", \"pearson\", or \"jaccard\".')\n",
    "        \n",
    "    def _pearson_similarity(self, x, y):\n",
    "        #effective if data can be transformed to normal distribution \n",
    "        pearson_sim= np.corrcoef(x,y)\n",
    "        return pearson_sim\n",
    "\n",
    "    def _jaccard_similarity(self, x, y):\n",
    "        '''when we calculate using 'len', we see how often each pairing of items come up in each basket transaction \n",
    "        (same row same column).\n",
    "        This means the 2 items are complimentary goods, and will have higher similarities. \n",
    "        Ideal for binary data, e.g. buy vs non-buy '''        \n",
    "        intersect_len=len(set(list(x)).intersection(list(y)))\n",
    "        union_len= len(list(x)) + len(list(y))- intersect_len\n",
    "        if union_len== 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return float(intersect_len)/union_len\n",
    "\n",
    "    def _cosine_similarity(self, x, y):\n",
    "        #returns cosine of angles between x and y\n",
    "        cos_sim= dot(x,y)/(norm(x)*norm(y))\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "382e3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self): \n",
    "        '''init Data class'''\n",
    "        self.data= None\n",
    "    \n",
    "    def load_data(self, filename, format='txt'):\n",
    "        '''loads data from excel, csv, tsv, or txt file'''\n",
    "        if format == 'excel':\n",
    "            self.data = pd.read_excel(filename)\n",
    "        elif format == 'csv':\n",
    "            self.data = pd.read_csv(filename)\n",
    "        elif format == 'tsv':\n",
    "            self.data = pd.read_csv(filename, sep='\\t')\n",
    "        elif format == 'txt':\n",
    "            self.data = pd.read_table(filename)\n",
    "        else:\n",
    "            raise ValueError('Invalid file format.  Please specify \"excel\", \"csv\", \"tsv\" or \"txt\".')\n",
    "        \n",
    " \n",
    "    def drop_small_orders(self, order_col='Member_number', min_order_size=None):\n",
    "        '''drop orders from self.data that have less than min_order_size unique items in basket'''\n",
    "        self.data=self.data[self.data.groupby(order_col)['itemDescription'].transform('count')>=min_order_size]\n",
    "        \n",
    "    def expand_columns(self, columns=[]):\n",
    "        #computes one-hot encoding on specified columns and appends them to self.data\n",
    "        dfs=[]\n",
    "        dfs.append(self.data)\n",
    "        for col in columns:\n",
    "            dfs.append(pd.get_dummies(self.data[col], prefix=None, sparse=False))\n",
    "        self.data = pd.concat(dfs, axis=1)\n",
    "        \n",
    "    def drop_columns(self, columns=[]):\n",
    "        #drops columns from self.data\n",
    "        self.data.drop(columns, axis=1, inplace=True)\n",
    "        return self.data\n",
    "        \n",
    "    def consolidate_orders(self, order_col='Member_number'):\n",
    "        #consolidates each order in self.data into single record.order number is maintained and all other columns summed.'''\n",
    "        self.data = self.data.groupby(order_col).sum().reset_index()\n",
    "        return self.data\n",
    "    \n",
    "    def get_columns(self):\n",
    "        data_columns= list(self.data.columns)\n",
    "        return data_columns\n",
    "    \n",
    "    def check_duplicates(self):\n",
    "        #check at the end after data consolidation\n",
    "        unique_rows= self.data.nunique()[0]\n",
    "        generic_rows= self.data.count()[0]\n",
    "        if unique_rows==generic_rows:\n",
    "            print('Data is good to go! No duplicates in unique identifier column')\n",
    "        else:\n",
    "            if generics_rows>unique_rows:\n",
    "                print('Duplicates found: {}'.format(generic_rows-unique_rows))\n",
    "            else:\n",
    "                print('Invalid data. Unique rows are greater than total rows. Please check data again')\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093058ca",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93702bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rec_engine=True\n",
    "user_col='Member_number'\n",
    "item_cols=data.get_columns()\n",
    "item_cols.remove(user_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab64d8f",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0cfae5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is good to go! No duplicates in unique identifier column\n"
     ]
    }
   ],
   "source": [
    "#Drop orders with few items, one-hot encode itemDescription category information, drop unnecessary columns, \n",
    "# and consolidate unique orders into single records\n",
    "data = Data()\n",
    "data.load_data('groceries_dataset.csv', format='csv')\n",
    "data.drop_small_orders(order_col='Member_number', min_order_size=1)\n",
    "data.expand_columns(['itemDescription'])  \n",
    "data.drop_columns(['Date'])\n",
    "data.consolidate_orders(order_col='Member_number')\n",
    "data.check_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f9d39",
   "metadata": {},
   "source": [
    "# Run Recommender Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b8167da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:18<00:00,  8.97it/s]\n",
      "  0%|                                                                                         | 0/3898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Instant food products  UHT-milk abrasive cleaner  \\\n",
      "Member_number                                                    \n",
      "1000                       0.003336  0.006288         0.003336   \n",
      "1001                       0.003079  0.006032         0.003079   \n",
      "1002                       0.002053  0.003722         0.002053   \n",
      "1003                       0.002053  0.003593         0.002053   \n",
      "1004                       0.005389  0.009625         0.005389   \n",
      "...                             ...       ...              ...   \n",
      "4996                       0.002566   0.00462         0.002566   \n",
      "4997                        0.00154  0.002823          0.00154   \n",
      "4998                       0.000513  0.001027         0.000513   \n",
      "4999                       0.004106   0.00693         0.004106   \n",
      "5000                       0.001796  0.003337         0.001796   \n",
      "\n",
      "              artif. sweetener baby cosmetics      bags baking powder  \\\n",
      "Member_number                                                           \n",
      "1000                  0.003336       0.003336  0.003336      0.005004   \n",
      "1001                  0.003079       0.003079  0.003079       0.00462   \n",
      "1002                  0.002053       0.002053  0.002053       0.00308   \n",
      "1003                  0.002053       0.002053  0.002053      0.002951   \n",
      "1004                  0.005389       0.005389  0.005389      0.007956   \n",
      "...                        ...            ...       ...           ...   \n",
      "4996                  0.002566       0.002566  0.002566      0.003721   \n",
      "4997                   0.00154        0.00154   0.00154       0.00231   \n",
      "4998                  0.000513       0.000513  0.000513       0.00077   \n",
      "4999                  0.004106       0.004106  0.004106      0.006031   \n",
      "5000                  0.001796       0.001796  0.001796      0.002695   \n",
      "\n",
      "              bathroom cleaner      beef   berries  ...    turkey   vinegar  \\\n",
      "Member_number                                       ...                       \n",
      "1000                  0.003336  0.006288  0.005004  ...  0.005004  0.005004   \n",
      "1001                  0.003079  0.006032   0.00462  ...   0.00462   0.00462   \n",
      "1002                  0.002053  0.003722   0.00308  ...   0.00308   0.00308   \n",
      "1003                  0.002053  0.003593  0.002951  ...  0.002951  0.002951   \n",
      "1004                  0.005389  0.009625  0.007956  ...  0.007956  0.007956   \n",
      "...                        ...       ...       ...  ...       ...       ...   \n",
      "4996                  0.002566   0.00462  0.003721  ...  0.003721  0.003721   \n",
      "4997                   0.00154  0.002823   0.00231  ...   0.00231   0.00231   \n",
      "4998                  0.000513  0.001027   0.00077  ...   0.00077   0.00077   \n",
      "4999                  0.004106   0.00693  0.006031  ...  0.006031  0.006031   \n",
      "5000                  0.001796  0.003337  0.002695  ...  0.002695  0.002695   \n",
      "\n",
      "                waffles whipped/sour cream    whisky white bread white wine  \\\n",
      "Member_number                                                                 \n",
      "1000           0.005004            0.00693  0.003336    0.005004   0.005004   \n",
      "1001            0.00462           0.006802  0.003079     0.00462    0.00462   \n",
      "1002            0.00308           0.004107  0.002053     0.00308    0.00308   \n",
      "1003           0.002951           0.004107  0.002053    0.002951   0.002951   \n",
      "1004           0.007956           0.011166  0.005389    0.007956   0.007956   \n",
      "...                 ...                ...       ...         ...        ...   \n",
      "4996           0.003721           0.005134  0.002566    0.003721   0.003721   \n",
      "4997            0.00231            0.00308   0.00154     0.00231    0.00231   \n",
      "4998            0.00077           0.001155  0.000513     0.00077    0.00077   \n",
      "4999           0.006031             0.0077  0.004106    0.006031   0.006031   \n",
      "5000           0.002695           0.003722  0.001796    0.002695   0.002695   \n",
      "\n",
      "              whole milk    yogurt  zwieback  \n",
      "Member_number                                 \n",
      "1000            0.007187   0.00693  0.003336  \n",
      "1001            0.007059  0.006802  0.003079  \n",
      "1002            0.004235  0.004107  0.002053  \n",
      "1003            0.004107  0.004107  0.002053  \n",
      "1004            0.011551  0.011166  0.005389  \n",
      "...                  ...       ...       ...  \n",
      "4996            0.005134  0.005134  0.002566  \n",
      "4997            0.003209   0.00308   0.00154  \n",
      "4998            0.001155  0.001155  0.000513  \n",
      "4999              0.0077    0.0077  0.004106  \n",
      "5000            0.003722  0.003722  0.001796  \n",
      "\n",
      "[3898 rows x 167 columns]\n",
      "We hope you will find these recommended items to your satisfaction should you purchase in the future!\n",
      " Thank you for shopping with us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3898/3898 [01:21<00:00, 47.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Member_number             Rec 1             Rec 2           Rec 3  \\\n",
      "0              1000        whole milk       brown bread            soda   \n",
      "1              1001        whole milk       brown bread            soda   \n",
      "2              1002        whole milk  other vegetables     brown bread   \n",
      "3              1003       brown bread              soda  tropical fruit   \n",
      "4              1004        whole milk  other vegetables     brown bread   \n",
      "...             ...               ...               ...             ...   \n",
      "3893           4996       brown bread              soda  tropical fruit   \n",
      "3894           4997        whole milk       brown bread            soda   \n",
      "3895           4998       brown bread              soda  tropical fruit   \n",
      "3896           4999  other vegetables       brown bread            soda   \n",
      "3897           5000  other vegetables       brown bread            soda   \n",
      "\n",
      "       Score 1   Score 2   Score 3  \n",
      "0     0.007187   0.00693   0.00693  \n",
      "1     0.007059  0.006802  0.006802  \n",
      "2     0.004235  0.004235  0.004107  \n",
      "3     0.004107  0.004107  0.004107  \n",
      "4     0.011551  0.011423  0.011166  \n",
      "...        ...       ...       ...  \n",
      "3893  0.005134  0.005134  0.005134  \n",
      "3894  0.003209   0.00308   0.00308  \n",
      "3895  0.001155  0.001155  0.001155  \n",
      "3896  0.007957    0.0077    0.0077  \n",
      "3897   0.00385  0.003722  0.003722  \n",
      "\n",
      "[3898 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if run_rec_engine:\n",
    "    rec_engine = Recommender(data.data, user_col=user_col, item_cols=item_cols, cf_method='item', similarity='jaccard')\n",
    "    rec_engine.create_similarity_matrix()\n",
    "    rec_engine.score_users()\n",
    "    rec_engine.generate_recs()\n",
    "    rec_engine.print_recs()\n",
    "    rec_engine.save_recs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
